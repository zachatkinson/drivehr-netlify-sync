#!/usr/bin/env tsx
/**
 * Production Job Data Browser
 *
 * Utility script to browse and analyze job data artifacts generated by
 * scrape-and-sync operations. Provides filtering, searching, statistics,
 * and detailed inspection of scraped job data.
 *
 * Usage:
 *   pnpm tsx scripts/browse-job-data.mts
 *   pnpm tsx scripts/browse-job-data.mts --latest
 *   pnpm tsx scripts/browse-job-data.mts --filter department=Engineering
 *   pnpm tsx scripts/browse-job-data.mts --stats
 *   pnpm tsx scripts/browse-job-data.mts --run-id 17103740786
 *
 * @since 1.0.0
 */

import { readdirSync, readFileSync, existsSync, statSync } from 'fs';
import { join } from 'path';
import type { NormalizedJob } from '../src/types/job.js';

/**
 * Job artifact file structure
 */
interface JobArtifact {
  timestamp: string;
  runId: string;
  totalJobs: number;
  jobs: NormalizedJob[];
}

/**
 * Log artifact file structure
 */
interface LogArtifact {
  timestamp: string;
  runId: string;
  result: {
    jobsScraped: number;
    jobsSynced: number;
    totalTime: number;
    success: boolean;
    error?: string;
    artifacts: {
      jobsFile?: string;
      logFile?: string;
      screenshotFile?: string;
    };
  };
  environment: {
    nodeVersion: string;
    platform: string;
    arch: string;
  };
}

/**
 * File info with parsed data
 */
interface ArtifactFile {
  filename: string;
  path: string;
  size: number;
  modified: Date;
  runId: string;
  timestamp: string;
  data: JobArtifact | LogArtifact;
  type: 'jobs' | 'log';
}

/**
 * CLI arguments interface
 */
interface CliArgs {
  latest: boolean;
  runId?: string;
  filter?: string;
  search?: string;
  stats: boolean;
  format: 'table' | 'json' | 'summary';
  limit?: number;
  help: boolean;
}

/**
 * Parse command line arguments
 */
function parseArgs(): CliArgs {
  const args = process.argv.slice(2);
  const parsed: CliArgs = {
    latest: false,
    stats: false,
    format: 'table',
    help: false,
  };

  for (let i = 0; i < args.length; i++) {
    const arg = args[i];
    switch (arg) {
      case '--latest':
        parsed.latest = true;
        break;
      case '--run-id':
        parsed.runId = args[i + 1];
        i++;
        break;
      case '--filter':
        parsed.filter = args[i + 1];
        i++;
        break;
      case '--search':
        parsed.search = args[i + 1];
        i++;
        break;
      case '--stats':
        parsed.stats = true;
        break;
      case '--format':
        parsed.format = args[i + 1] as 'table' | 'json' | 'summary';
        i++;
        break;
      case '--limit':
        parsed.limit = parseInt(args[i + 1], 10);
        i++;
        break;
      case '--help':
      case '-h':
        parsed.help = true;
        break;
    }
  }

  return parsed;
}

/**
 * Display help information
 */
function showHelp(): void {
  console.log(`
üóÇÔ∏è  Production Job Data Browser

Browse and analyze job data artifacts from scrape-and-sync operations.

Usage:
  pnpm tsx scripts/browse-job-data.mts [options]

Options:
  --latest           Show only the most recent job data
  --run-id <id>      Show data for specific GitHub Actions run ID
  --filter <expr>    Filter jobs (e.g., department=Engineering, location=Remote)
  --search <term>    Search in job titles and descriptions
  --stats            Show detailed statistics
  --format <type>    Output format: table, json, summary (default: table)
  --limit <n>        Limit number of jobs shown
  --help, -h         Show this help message

Examples:
  pnpm tsx scripts/browse-job-data.mts --latest
  pnpm tsx scripts/browse-job-data.mts --run-id 17103740786
  pnpm tsx scripts/browse-job-data.mts --filter department=Engineering --limit 5
  pnpm tsx scripts/browse-job-data.mts --search "software engineer" --stats
  pnpm tsx scripts/browse-job-data.mts --latest --format json
`);
}

/**
 * Find all artifact files
 */
function findArtifacts(): ArtifactFile[] {
  const artifacts: ArtifactFile[] = [];
  const directories = ['./jobs', './logs'];

  directories.forEach(dir => {
    if (!existsSync(dir)) {
      console.log(`‚ö†Ô∏è  Directory ${dir} does not exist. Run scrape-and-sync to generate artifacts.`);
      return;
    }

    const files = readdirSync(dir);
    
    files.forEach(filename => {
      const filepath = join(dir, filename);
      const stats = statSync(filepath);
      
      if (!stats.isFile() || !filename.endsWith('.json')) {
        return;
      }

      try {
        const content = readFileSync(filepath, 'utf8');
        const data = JSON.parse(content);

        // Determine file type and extract metadata
        let type: 'jobs' | 'log';
        let runId: string;
        let timestamp: string;

        if ('jobs' in data && Array.isArray(data.jobs)) {
          type = 'jobs';
          runId = data.runId || 'unknown';
          timestamp = data.timestamp || stats.mtime.toISOString();
        } else if ('result' in data) {
          type = 'log';
          runId = data.runId || 'unknown';
          timestamp = data.timestamp || stats.mtime.toISOString();
        } else {
          return; // Skip unknown format
        }

        artifacts.push({
          filename,
          path: filepath,
          size: stats.size,
          modified: stats.mtime,
          runId,
          timestamp,
          data,
          type,
        });

      } catch (error) {
        console.warn(`‚ö†Ô∏è  Could not parse ${filename}: ${error instanceof Error ? error.message : 'Unknown error'}`);
      }
    });
  });

  // Sort by timestamp, newest first
  return artifacts.sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());
}

/**
 * Filter jobs based on criteria
 */
function filterJobs(jobs: NormalizedJob[], filter: string): NormalizedJob[] {
  if (!filter) return jobs;

  const [field, value] = filter.split('=');
  if (!field || !value) {
    console.warn(`‚ö†Ô∏è  Invalid filter format. Use field=value (e.g., department=Engineering)`);
    return jobs;
  }

  return jobs.filter(job => {
    const jobValue = job[field as keyof NormalizedJob];
    if (typeof jobValue === 'string') {
      return jobValue.toLowerCase().includes(value.toLowerCase());
    }
    return false;
  });
}

/**
 * Search jobs by title or description
 */
function searchJobs(jobs: NormalizedJob[], searchTerm: string): NormalizedJob[] {
  if (!searchTerm) return jobs;

  const term = searchTerm.toLowerCase();
  return jobs.filter(job => 
    job.title.toLowerCase().includes(term) ||
    (job.description && job.description.toLowerCase().includes(term))
  );
}

/**
 * Calculate statistics for jobs
 */
function calculateStats(jobs: NormalizedJob[]): void {
  console.log(`üìä Job Statistics`);
  console.log('='.repeat(18));
  console.log();

  console.log(`Total Jobs: ${jobs.length}`);
  console.log();

  // Department breakdown
  const deptCounts = jobs.reduce((acc, job) => {
    const dept = job.department || 'Unknown';
    acc[dept] = (acc[dept] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  console.log(`üìã By Department:`);
  Object.entries(deptCounts)
    .sort(([,a], [,b]) => b - a)
    .forEach(([dept, count]) => {
      console.log(`   ${dept.padEnd(20)} ${count.toString().padStart(3)} jobs`);
    });
  console.log();

  // Location breakdown
  const locationCounts = jobs.reduce((acc, job) => {
    const location = job.location || 'Unknown';
    acc[location] = (acc[location] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  console.log(`üåç By Location:`);
  Object.entries(locationCounts)
    .sort(([,a], [,b]) => b - a)
    .slice(0, 10) // Top 10 locations
    .forEach(([location, count]) => {
      console.log(`   ${location.padEnd(20)} ${count.toString().padStart(3)} jobs`);
    });
  if (Object.keys(locationCounts).length > 10) {
    console.log(`   ... and ${Object.keys(locationCounts).length - 10} more locations`);
  }
  console.log();

  // Job type breakdown
  const typeCounts = jobs.reduce((acc, job) => {
    const type = job.type || 'Unknown';
    acc[type] = (acc[type] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  console.log(`üíº By Job Type:`);
  Object.entries(typeCounts)
    .sort(([,a], [,b]) => b - a)
    .forEach(([type, count]) => {
      console.log(`   ${type.padEnd(20)} ${count.toString().padStart(3)} jobs`);
    });
  console.log();

  // Source breakdown
  const sourceCounts = jobs.reduce((acc, job) => {
    acc[job.source] = (acc[job.source] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  console.log(`üîó By Source:`);
  Object.entries(sourceCounts)
    .sort(([,a], [,b]) => b - a)
    .forEach(([source, count]) => {
      console.log(`   ${source.padEnd(20)} ${count.toString().padStart(3)} jobs`);
    });
  console.log();

  // Recent postings
  const recentJobs = jobs
    .filter(job => job.postedDate)
    .sort((a, b) => new Date(b.postedDate!).getTime() - new Date(a.postedDate!).getTime())
    .slice(0, 5);

  if (recentJobs.length > 0) {
    console.log(`üÜï Most Recent Postings:`);
    recentJobs.forEach(job => {
      const date = new Date(job.postedDate!).toLocaleDateString();
      console.log(`   ${date} - ${job.title} (${job.department || 'Unknown'})`);
    });
    console.log();
  }
}

/**
 * Display jobs in table format
 */
function displayJobsTable(jobs: NormalizedJob[]): void {
  if (jobs.length === 0) {
    console.log('No jobs found matching your criteria.\n');
    return;
  }

  // Calculate column widths
  const widths = {
    title: Math.min(40, Math.max(5, Math.max(...jobs.map(j => j.title.length)))),
    department: Math.min(15, Math.max(10, Math.max(...jobs.map(j => (j.department || '').length)))),
    location: Math.min(20, Math.max(8, Math.max(...jobs.map(j => (j.location || '').length)))),
    type: Math.max(4, Math.max(...jobs.map(j => (j.type || '').length))),
    posted: 10,
  };

  // Header
  const header = [
    'TITLE'.padEnd(widths.title),
    'DEPARTMENT'.padEnd(widths.department),
    'LOCATION'.padEnd(widths.location),
    'TYPE'.padEnd(widths.type),
    'POSTED'.padEnd(widths.posted),
  ].join(' | ');

  console.log(header);
  console.log('-'.repeat(header.length));

  // Rows
  jobs.forEach(job => {
    const title = job.title.length > widths.title 
      ? job.title.substring(0, widths.title - 3) + '...'
      : job.title;
    
    const department = (job.department || '').length > widths.department
      ? (job.department || '').substring(0, widths.department - 3) + '...'
      : (job.department || '');
      
    const location = (job.location || '').length > widths.location
      ? (job.location || '').substring(0, widths.location - 3) + '...'
      : (job.location || '');

    const posted = job.postedDate 
      ? new Date(job.postedDate).toLocaleDateString()
      : '';

    const row = [
      title.padEnd(widths.title),
      department.padEnd(widths.department),
      location.padEnd(widths.location),
      (job.type || '').padEnd(widths.type),
      posted.padEnd(widths.posted),
    ].join(' | ');
    
    console.log(row);
  });

  console.log();
}

/**
 * Display artifact list
 */
function displayArtifacts(artifacts: ArtifactFile[]): void {
  console.log(`üóÇÔ∏è  Available Artifacts (${artifacts.length} files)`);
  console.log('='.repeat(30));
  console.log();

  if (artifacts.length === 0) {
    console.log('No job artifacts found. Run scrape-and-sync to generate data.');
    console.log();
    return;
  }

  artifacts.forEach(artifact => {
    const date = new Date(artifact.timestamp).toLocaleString();
    const sizeKb = Math.round(artifact.size / 1024);
    
    if (artifact.type === 'jobs') {
      const jobData = artifact.data as JobArtifact;
      console.log(`üìÑ ${artifact.filename}`);
      console.log(`   Run ID: ${artifact.runId}`);
      console.log(`   Date: ${date}`);
      console.log(`   Jobs: ${jobData.totalJobs}`);
      console.log(`   Size: ${sizeKb}KB`);
    } else {
      const logData = artifact.data as LogArtifact;
      console.log(`üìã ${artifact.filename}`);
      console.log(`   Run ID: ${artifact.runId}`);
      console.log(`   Date: ${date}`);
      console.log(`   Success: ${logData.result.success ? '‚úÖ' : '‚ùå'}`);
      console.log(`   Jobs: ${logData.result.jobsScraped} scraped, ${logData.result.jobsSynced} synced`);
      console.log(`   Size: ${sizeKb}KB`);
    }
    console.log();
  });
}

/**
 * Main execution function
 */
function main(): void {
  const args = parseArgs();

  if (args.help) {
    showHelp();
    return;
  }

  console.log('üóÇÔ∏è  Production Job Data Browser\n');

  const artifacts = findArtifacts();
  
  if (artifacts.length === 0) {
    console.log('‚ùå No artifacts found. Run the scrape-and-sync script to generate job data.');
    console.log('   Expected directories: ./jobs/, ./logs/');
    return;
  }

  // Show artifact list if no specific data requested
  if (!args.latest && !args.runId && !args.stats) {
    displayArtifacts(artifacts);
    console.log(`üí° Use --latest to see the most recent job data`);
    console.log(`üí° Use --run-id <id> to see specific run data`);
    console.log(`üí° Use --stats to see detailed statistics`);
    return;
  }

  // Filter artifacts based on criteria
  let selectedArtifacts = artifacts.filter(a => a.type === 'jobs');

  if (args.runId) {
    selectedArtifacts = selectedArtifacts.filter(a => a.runId === args.runId);
    if (selectedArtifacts.length === 0) {
      console.log(`‚ùå No job data found for run ID: ${args.runId}`);
      console.log(`Available run IDs: ${artifacts.map(a => a.runId).join(', ')}`);
      return;
    }
  }

  if (args.latest) {
    selectedArtifacts = selectedArtifacts.slice(0, 1);
  }

  // Process selected artifacts
  selectedArtifacts.forEach((artifact, index) => {
    const jobData = artifact.data as JobArtifact;
    let jobs = jobData.jobs;

    // Apply filters
    if (args.filter) {
      jobs = filterJobs(jobs, args.filter);
    }

    if (args.search) {
      jobs = searchJobs(jobs, args.search);
    }

    if (args.limit && args.limit > 0) {
      jobs = jobs.slice(0, args.limit);
    }

    // Display header
    const artifactDate = new Date(artifact.timestamp).toLocaleString();
    console.log(`üìä Run ID: ${artifact.runId} (${artifactDate})`);
    console.log(`Original: ${jobData.totalJobs} jobs | Filtered: ${jobs.length} jobs`);
    console.log();

    // Display data
    if (args.stats) {
      calculateStats(jobs);
    }

    if (args.format === 'json') {
      console.log(JSON.stringify(jobs, null, 2));
    } else if (args.format === 'summary') {
      console.log(`üìã Summary: ${jobs.length} jobs found`);
      const depts = [...new Set(jobs.map(j => j.department).filter(Boolean))];
      const locations = [...new Set(jobs.map(j => j.location).filter(Boolean))];
      console.log(`Departments: ${depts.join(', ')}`);
      console.log(`Locations: ${locations.slice(0, 5).join(', ')}${locations.length > 5 ? '...' : ''}`);
    } else {
      displayJobsTable(jobs);
    }

    if (index < selectedArtifacts.length - 1) {
      console.log('‚îÄ'.repeat(80));
      console.log();
    }
  });
}

// Execute if run directly
if (import.meta.url === `file://${process.argv[1]}`) {
  main();
}

export { findArtifacts, filterJobs, searchJobs, calculateStats };