#!/usr/bin/env tsx
/**
 * Production Job Data Browser for DriveHR Netlify Sync
 *
 * Enterprise-grade command-line utility for browsing, analyzing, and filtering
 * job data artifacts generated by scrape-and-sync operations. Supports multiple
 * output formats, statistical analysis, and comprehensive search capabilities
 * for production debugging and data verification workflows.
 *
 * Features:
 * - Browse job artifacts from GitHub Actions runs
 * - Filter by department, location, job type, and custom criteria
 * - Search functionality across job titles and descriptions
 * - Statistical analysis with breakdowns by various dimensions
 * - Multiple output formats (table, JSON, summary)
 * - Production-ready error handling and validation
 *
 * @example
 * ```typescript
 * // Show latest job data
 * pnpm tsx scripts/browse-job-data.mts --latest
 *
 * // Filter engineering jobs with statistics
 * pnpm tsx scripts/browse-job-data.mts --filter department=Engineering --stats
 *
 * // Search for specific roles in JSON format
 * pnpm tsx scripts/browse-job-data.mts --search "software engineer" --format json
 * ```
 *
 * @module browse-job-data
 * @since 1.0.0
 * @see {@link ../src/types/job.ts} for job data structures
 * @see {@link ../CLAUDE.md} for development standards
 */

import { readdirSync, readFileSync, existsSync, statSync } from 'fs';
import { join } from 'path';
import type { NormalizedJob } from '../src/types/job.js';

/**
 * Job artifact data structure from scrape-and-sync operations
 *
 * Contains the complete job dataset along with metadata from a specific
 * GitHub Actions run. This structure is generated by the sync-jobs function
 * and represents the normalized job data ready for WordPress integration.
 *
 * @since 1.0.0
 */
interface JobArtifact {
  /** ISO timestamp when the artifact was created */
  timestamp: string;
  /** GitHub Actions run ID that generated this artifact */
  runId: string;
  /** Total number of jobs in the dataset */
  totalJobs: number;
  /** Array of normalized job data */
  jobs: NormalizedJob[];
}

/**
 * Log artifact data structure from scrape-and-sync operations
 *
 * Contains execution metadata, performance metrics, and environment information
 * from a scrape-and-sync operation. Used for debugging, monitoring, and
 * performance analysis of the job synchronization process.
 *
 * @since 1.0.0
 */
interface LogArtifact {
  /** ISO timestamp when the log was created */
  timestamp: string;
  /** GitHub Actions run ID that generated this log */
  runId: string;
  /** Execution results and metrics */
  result: {
    /** Number of jobs successfully scraped from source */
    jobsScraped: number;
    /** Number of jobs successfully synchronized to WordPress */
    jobsSynced: number;
    /** Total execution time in milliseconds */
    totalTime: number;
    /** Whether the operation completed successfully */
    success: boolean;
    /** Error message if operation failed */
    error?: string;
    /** Generated artifact file paths */
    artifacts: {
      /** Path to jobs data file */
      jobsFile?: string;
      /** Path to execution log file */
      logFile?: string;
      /** Path to debug screenshot file */
      screenshotFile?: string;
    };
  };
  /** Runtime environment information */
  environment: {
    /** Node.js version used */
    nodeVersion: string;
    /** Operating system platform */
    platform: string;
    /** System architecture */
    arch: string;
  };
}

/**
 * Unified artifact file metadata and content structure
 *
 * Represents both job and log artifacts with their filesystem metadata.
 * Used internally by the browser to manage and display artifact information
 * with consistent handling regardless of artifact type.
 *
 * @since 1.0.0
 */
interface ArtifactFile {
  /** Original filename on filesystem */
  filename: string;
  /** Full filesystem path to the artifact */
  path: string;
  /** File size in bytes */
  size: number;
  /** Last modification timestamp from filesystem */
  modified: Date;
  /** GitHub Actions run ID from artifact content */
  runId: string;
  /** Creation timestamp from artifact content */
  timestamp: string;
  /** Parsed artifact content */
  data: JobArtifact | LogArtifact;
  /** Discriminator for artifact type */
  type: 'jobs' | 'log';
}

/**
 * Command line arguments configuration for job data browser
 *
 * Defines all available CLI options for filtering, searching, and formatting
 * job data output. Supports flexible workflows for data analysis and debugging.
 *
 * @since 1.0.0
 */
interface CliArgs {
  /** Show only the most recent job data */
  latest: boolean;
  /** Filter to specific GitHub Actions run ID */
  runId?: string;
  /** Field-based filter expression (e.g., "department=Engineering") */
  filter?: string;
  /** Search term for titles and descriptions */
  search?: string;
  /** Display detailed statistical analysis */
  stats: boolean;
  /** Output format preference */
  format: 'table' | 'json' | 'summary';
  /** Maximum number of jobs to display */
  limit?: number;
  /** Show help information */
  help: boolean;
}

/**
 * Parse command line arguments into structured configuration
 *
 * Processes argv to extract user preferences for data filtering, output formatting,
 * and analysis options. Provides sensible defaults while supporting comprehensive
 * customization for different debugging and analysis workflows.
 *
 * @returns Parsed CLI arguments with defaults applied
 * @example
 * ```typescript
 * const args = parseArgs();
 * if (args.help) {
 *   showHelp();
 *   return;
 * }
 * console.log(`Format: ${args.format}, Stats: ${args.stats}`);
 * ```
 * @since 1.0.0
 */
function parseArgs(): CliArgs {
  const args = process.argv.slice(2);
  const parsed: CliArgs = {
    latest: false,
    stats: false,
    format: 'table',
    help: false,
  };

  for (let i = 0; i < args.length; i++) {
    const arg = args[i];
    switch (arg) {
      case '--latest':
        parsed.latest = true;
        break;
      case '--run-id':
        parsed.runId = args[i + 1];
        i++;
        break;
      case '--filter':
        parsed.filter = args[i + 1];
        i++;
        break;
      case '--search':
        parsed.search = args[i + 1];
        i++;
        break;
      case '--stats':
        parsed.stats = true;
        break;
      case '--format':
        parsed.format = args[i + 1] as 'table' | 'json' | 'summary';
        i++;
        break;
      case '--limit':
        parsed.limit = parseInt(args[i + 1], 10);
        i++;
        break;
      case '--help':
      case '-h':
        parsed.help = true;
        break;
    }
  }

  return parsed;
}

/**
 * Display comprehensive help information for job data browser
 *
 * Shows usage instructions, available options, and practical examples to guide
 * users through the various capabilities of the job data browser. Designed for
 * both interactive use and documentation reference.
 *
 * @example
 * ```typescript
 * showHelp();
 * // Outputs formatted help text with usage examples
 * ```
 * @since 1.0.0
 */
function showHelp(): void {
  console.log(`
üóÇÔ∏è  Production Job Data Browser

Browse and analyze job data artifacts from scrape-and-sync operations.

Usage:
  pnpm tsx scripts/browse-job-data.mts [options]

Options:
  --latest           Show only the most recent job data
  --run-id <id>      Show data for specific GitHub Actions run ID
  --filter <expr>    Filter jobs (e.g., department=Engineering, location=Remote)
  --search <term>    Search in job titles and descriptions
  --stats            Show detailed statistics
  --format <type>    Output format: table, json, summary (default: table)
  --limit <n>        Limit number of jobs shown
  --help, -h         Show this help message

Examples:
  pnpm tsx scripts/browse-job-data.mts --latest
  pnpm tsx scripts/browse-job-data.mts --run-id 17103740786
  pnpm tsx scripts/browse-job-data.mts --filter department=Engineering --limit 5
  pnpm tsx scripts/browse-job-data.mts --search "software engineer" --stats
  pnpm tsx scripts/browse-job-data.mts --latest --format json
`);
}

/**
 * Discover and parse job artifacts from filesystem
 *
 * Scans jobs and logs directories for JSON artifacts, parses their content,
 * and returns structured metadata sorted by timestamp. Handles both job data
 * artifacts and execution log artifacts with comprehensive error handling.
 *
 * @returns Array of artifact files sorted by timestamp (newest first)
 * @throws {Error} When JSON parsing fails (handled gracefully with warnings)
 * @example
 * ```typescript
 * const artifacts = findArtifacts();
 * console.log(`Found ${artifacts.length} artifacts`);
 * artifacts.forEach(artifact => {
 *   console.log(`${artifact.type}: ${artifact.filename}`);
 * });
 * ```
 * @since 1.0.0
 */
function findArtifacts(): ArtifactFile[] {
  const artifacts: ArtifactFile[] = [];
  const directories = ['./jobs', './logs'];

  directories.forEach(dir => {
    if (!existsSync(dir)) {
      console.log(`‚ö†Ô∏è  Directory ${dir} does not exist. Run scrape-and-sync to generate artifacts.`);
      return;
    }

    const files = readdirSync(dir);
    
    files.forEach(filename => {
      const filepath = join(dir, filename);
      const stats = statSync(filepath);
      
      if (!stats.isFile() || !filename.endsWith('.json')) {
        return;
      }

      try {
        const content = readFileSync(filepath, 'utf8');
        const data = JSON.parse(content);

        // Determine file type and extract metadata
        let type: 'jobs' | 'log';
        let runId: string;
        let timestamp: string;

        if ('jobs' in data && Array.isArray(data.jobs)) {
          type = 'jobs';
          runId = data.runId || 'unknown';
          timestamp = data.timestamp || stats.mtime.toISOString();
        } else if ('result' in data) {
          type = 'log';
          runId = data.runId || 'unknown';
          timestamp = data.timestamp || stats.mtime.toISOString();
        } else {
          return; // Skip unknown format
        }

        // Validate data structure before type assertion
        if ((type === 'jobs' && data.jobs && Array.isArray(data.jobs)) ||
            (type === 'log' && data.result && typeof data.result === 'object')) {
          artifacts.push({
            filename,
            path: filepath,
            size: stats.size,
            modified: stats.mtime,
            runId,
            timestamp,
            data: data as JobArtifact | LogArtifact,
            type,
          });
        }

      } catch (error) {
        console.warn(`‚ö†Ô∏è  Could not parse ${filename}: ${error instanceof Error ? error.message : 'Unknown error'}`);
      }
    });
  });

  // Sort by timestamp, newest first
  return artifacts.sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());
}

/**
 * Filter job data by field-value criteria
 *
 * Applies field-based filtering using "field=value" syntax to narrow job results.
 * Supports case-insensitive matching and handles invalid filter formats gracefully.
 * Commonly used for department, location, and job type filtering.
 *
 * @param jobs - Array of normalized job data to filter
 * @param filter - Filter expression in "field=value" format
 * @returns Filtered job array matching the criteria
 * @example
 * ```typescript
 * const engineeringJobs = filterJobs(allJobs, 'department=Engineering');
 * const remoteJobs = filterJobs(allJobs, 'location=Remote');
 * const fullTimeJobs = filterJobs(allJobs, 'type=Full-time');
 * ```
 * @since 1.0.0
 */
function filterJobs(jobs: NormalizedJob[], filter: string): NormalizedJob[] {
  if (!filter) return jobs;

  const [field, value] = filter.split('=');
  if (!field || !value) {
    console.warn(`‚ö†Ô∏è  Invalid filter format. Use field=value (e.g., department=Engineering)`);
    return jobs;
  }

  return jobs.filter(job => {
    const jobValue = job[field as keyof NormalizedJob];
    if (typeof jobValue === 'string') {
      return jobValue.toLowerCase().includes(value.toLowerCase());
    }
    return false;
  });
}

/**
 * Search job data by title and description content
 *
 * Performs case-insensitive text search across job titles and descriptions
 * to find relevant positions. Useful for finding specific technologies,
 * skills, or role types within the job dataset.
 *
 * @param jobs - Array of normalized job data to search
 * @param searchTerm - Text to search for in titles and descriptions
 * @returns Jobs containing the search term
 * @example
 * ```typescript
 * const softwareJobs = searchJobs(allJobs, 'software engineer');
 * const reactJobs = searchJobs(allJobs, 'React');
 * const seniorRoles = searchJobs(allJobs, 'senior');
 * ```
 * @since 1.0.0
 */
function searchJobs(jobs: NormalizedJob[], searchTerm: string): NormalizedJob[] {
  if (!searchTerm) return jobs;

  const term = searchTerm.toLowerCase();
  return jobs.filter(job => 
    job.title.toLowerCase().includes(term) ||
    (job.description && job.description.toLowerCase().includes(term))
  );
}

/**
 * Generate and display comprehensive job statistics
 *
 * Analyzes job data to produce detailed breakdowns by department, location,
 * job type, and source. Includes recent postings analysis and formatted
 * console output for data insights and trend analysis.
 *
 * @param jobs - Array of normalized job data to analyze
 * @example
 * ```typescript
 * calculateStats(engineeringJobs);
 * // Outputs:
 * // üìä Job Statistics
 * // Total Jobs: 45
 * // üìã By Department:
 * //    Engineering          35 jobs
 * //    Product               8 jobs
 * //    Design                2 jobs
 * ```
 * @since 1.0.0
 */
function calculateStats(jobs: NormalizedJob[]): void {
  console.log(`üìä Job Statistics`);
  console.log('='.repeat(18));
  console.log();

  console.log(`Total Jobs: ${jobs.length}`);
  console.log();

  // Department breakdown
  const deptCounts = jobs.reduce((acc, job) => {
    const dept = job.department || 'Unknown';
    acc[dept] = (acc[dept] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  console.log(`üìã By Department:`);
  Object.entries(deptCounts)
    .sort(([,a], [,b]) => b - a)
    .forEach(([dept, count]) => {
      console.log(`   ${dept.padEnd(20)} ${count.toString().padStart(3)} jobs`);
    });
  console.log();

  // Location breakdown
  const locationCounts = jobs.reduce((acc, job) => {
    const location = job.location || 'Unknown';
    acc[location] = (acc[location] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  console.log(`üåç By Location:`);
  Object.entries(locationCounts)
    .sort(([,a], [,b]) => b - a)
    .slice(0, 10) // Top 10 locations
    .forEach(([location, count]) => {
      console.log(`   ${location.padEnd(20)} ${count.toString().padStart(3)} jobs`);
    });
  if (Object.keys(locationCounts).length > 10) {
    console.log(`   ... and ${Object.keys(locationCounts).length - 10} more locations`);
  }
  console.log();

  // Job type breakdown
  const typeCounts = jobs.reduce((acc, job) => {
    const type = job.type || 'Unknown';
    acc[type] = (acc[type] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  console.log(`üíº By Job Type:`);
  Object.entries(typeCounts)
    .sort(([,a], [,b]) => b - a)
    .forEach(([type, count]) => {
      console.log(`   ${type.padEnd(20)} ${count.toString().padStart(3)} jobs`);
    });
  console.log();

  // Source breakdown
  const sourceCounts = jobs.reduce((acc, job) => {
    acc[job.source] = (acc[job.source] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  console.log(`üîó By Source:`);
  Object.entries(sourceCounts)
    .sort(([,a], [,b]) => b - a)
    .forEach(([source, count]) => {
      console.log(`   ${source.padEnd(20)} ${count.toString().padStart(3)} jobs`);
    });
  console.log();

  // Recent postings
  const recentJobs = jobs
    .filter(job => job.postedDate)
    .sort((a, b) => new Date(b.postedDate!).getTime() - new Date(a.postedDate!).getTime())
    .slice(0, 5);

  if (recentJobs.length > 0) {
    console.log(`üÜï Most Recent Postings:`);
    recentJobs.forEach(job => {
      const date = new Date(job.postedDate!).toLocaleDateString();
      console.log(`   ${date} - ${job.title} (${job.department || 'Unknown'})`);
    });
    console.log();
  }
}

/**
 * Display job data in formatted table layout
 *
 * Renders job information in a console-friendly table format with dynamic
 * column sizing, text truncation, and proper alignment. Handles empty datasets
 * gracefully and provides clear visual separation between data elements.
 *
 * @param jobs - Array of job data to display in table format
 * @example
 * ```typescript
 * displayJobsTable(filteredJobs);
 * // Outputs formatted table:
 * // TITLE                    | DEPARTMENT | LOCATION     | TYPE      | POSTED
 * // Senior Software Engineer | Engineering| San Francisco| Full-time | 1/15/2024
 * ```
 * @since 1.0.0
 */
function displayJobsTable(jobs: NormalizedJob[]): void {
  if (jobs.length === 0) {
    console.log('No jobs found matching your criteria.\n');
    return;
  }

  // Calculate column widths
  const widths = {
    title: Math.min(40, Math.max(5, Math.max(...jobs.map(j => j.title.length)))),
    department: Math.min(15, Math.max(10, Math.max(...jobs.map(j => (j.department || '').length)))),
    location: Math.min(20, Math.max(8, Math.max(...jobs.map(j => (j.location || '').length)))),
    type: Math.max(4, Math.max(...jobs.map(j => (j.type || '').length))),
    posted: 10,
  };

  // Header
  const header = [
    'TITLE'.padEnd(widths.title),
    'DEPARTMENT'.padEnd(widths.department),
    'LOCATION'.padEnd(widths.location),
    'TYPE'.padEnd(widths.type),
    'POSTED'.padEnd(widths.posted),
  ].join(' | ');

  console.log(header);
  console.log('-'.repeat(header.length));

  // Rows
  jobs.forEach(job => {
    const title = job.title.length > widths.title 
      ? job.title.substring(0, widths.title - 3) + '...'
      : job.title;
    
    const department = (job.department || '').length > widths.department
      ? (job.department || '').substring(0, widths.department - 3) + '...'
      : (job.department || '');
      
    const location = (job.location || '').length > widths.location
      ? (job.location || '').substring(0, widths.location - 3) + '...'
      : (job.location || '');

    const posted = job.postedDate 
      ? new Date(job.postedDate).toLocaleDateString()
      : '';

    const row = [
      title.padEnd(widths.title),
      department.padEnd(widths.department),
      location.padEnd(widths.location),
      (job.type || '').padEnd(widths.type),
      posted.padEnd(widths.posted),
    ].join(' | ');
    
    console.log(row);
  });

  console.log();
}

/**
 * Display available artifacts with metadata summary
 *
 * Shows comprehensive overview of discovered artifacts including timestamps,
 * file sizes, job counts, and execution status. Provides users with context
 * about available data before detailed analysis.
 *
 * @param artifacts - Array of artifact files to display
 * @example
 * ```typescript
 * displayArtifacts(foundArtifacts);
 * // Outputs:
 * // üóÇÔ∏è  Available Artifacts (3 files)
 * // üìÑ jobs-20240115-143022.json
 * //    Run ID: 7654321
 * //    Jobs: 45
 * //    Size: 15KB
 * ```
 * @since 1.0.0
 */
function displayArtifacts(artifacts: ArtifactFile[]): void {
  console.log(`üóÇÔ∏è  Available Artifacts (${artifacts.length} files)`);
  console.log('='.repeat(30));
  console.log();

  if (artifacts.length === 0) {
    console.log('No job artifacts found. Run scrape-and-sync to generate data.');
    console.log();
    return;
  }

  artifacts.forEach(artifact => {
    const date = new Date(artifact.timestamp).toLocaleString();
    const sizeKb = Math.round(artifact.size / 1024);
    
    if (artifact.type === 'jobs') {
      // Safe type assertion: artifact.type ensures this is JobArtifact
      const jobData = artifact.data as JobArtifact;
      console.log(`üìÑ ${artifact.filename}`);
      console.log(`   Run ID: ${artifact.runId}`);
      console.log(`   Date: ${date}`);
      console.log(`   Jobs: ${jobData.totalJobs}`);
      console.log(`   Size: ${sizeKb}KB`);
    } else {
      // Safe type assertion: artifact.type ensures this is LogArtifact  
      const logData = artifact.data as LogArtifact;
      console.log(`üìã ${artifact.filename}`);
      console.log(`   Run ID: ${artifact.runId}`);
      console.log(`   Date: ${date}`);
      console.log(`   Success: ${logData.result.success ? '‚úÖ' : '‚ùå'}`);
      console.log(`   Jobs: ${logData.result.jobsScraped} scraped, ${logData.result.jobsSynced} synced`);
      console.log(`   Size: ${sizeKb}KB`);
    }
    console.log();
  });
}

/**
 * Main execution orchestrator for job data browser
 *
 * Coordinates the complete workflow from argument parsing through data discovery,
 * filtering, and presentation. Implements the primary business logic for the
 * browser tool with comprehensive error handling and user guidance.
 *
 * Workflow:
 * 1. Parse and validate command line arguments
 * 2. Discover and load available artifacts
 * 3. Apply user-specified filters and search criteria
 * 4. Present data in requested format with optional statistics
 *
 * @example
 * ```typescript
 * main();
 * // Executes complete browser workflow based on CLI arguments
 * ```
 * @since 1.0.0
 */
function main(): void {
  const args = parseArgs();

  if (args.help) {
    showHelp();
    return;
  }

  console.log('üóÇÔ∏è  Production Job Data Browser\n');

  const artifacts = findArtifacts();
  
  if (artifacts.length === 0) {
    console.log('‚ùå No artifacts found. Run the scrape-and-sync script to generate job data.');
    console.log('   Expected directories: ./jobs/, ./logs/');
    return;
  }

  // Show artifact list if no specific data requested
  if (!args.latest && !args.runId && !args.stats) {
    displayArtifacts(artifacts);
    console.log(`üí° Use --latest to see the most recent job data`);
    console.log(`üí° Use --run-id <id> to see specific run data`);
    console.log(`üí° Use --stats to see detailed statistics`);
    return;
  }

  // Filter artifacts based on criteria
  let selectedArtifacts = artifacts.filter(a => a.type === 'jobs');

  if (args.runId) {
    selectedArtifacts = selectedArtifacts.filter(a => a.runId === args.runId);
    if (selectedArtifacts.length === 0) {
      console.log(`‚ùå No job data found for run ID: ${args.runId}`);
      console.log(`Available run IDs: ${artifacts.map(a => a.runId).join(', ')}`);
      return;
    }
  }

  if (args.latest) {
    selectedArtifacts = selectedArtifacts.slice(0, 1);
  }

  // Process selected artifacts
  selectedArtifacts.forEach((artifact, index) => {
    // Safe type assertion: selectedArtifacts filtered to jobs type only
    const jobData = artifact.data as JobArtifact;
    let jobs = jobData.jobs;

    // Apply filters
    if (args.filter) {
      jobs = filterJobs(jobs, args.filter);
    }

    if (args.search) {
      jobs = searchJobs(jobs, args.search);
    }

    if (args.limit && args.limit > 0) {
      jobs = jobs.slice(0, args.limit);
    }

    // Display header
    const artifactDate = new Date(artifact.timestamp).toLocaleString();
    console.log(`üìä Run ID: ${artifact.runId} (${artifactDate})`);
    console.log(`Original: ${jobData.totalJobs} jobs | Filtered: ${jobs.length} jobs`);
    console.log();

    // Display data
    if (args.stats) {
      calculateStats(jobs);
    }

    if (args.format === 'json') {
      console.log(JSON.stringify(jobs, null, 2));
    } else if (args.format === 'summary') {
      console.log(`üìã Summary: ${jobs.length} jobs found`);
      const depts = [...new Set(jobs.map(j => j.department).filter(Boolean))];
      const locations = [...new Set(jobs.map(j => j.location).filter(Boolean))];
      console.log(`Departments: ${depts.join(', ')}`);
      console.log(`Locations: ${locations.slice(0, 5).join(', ')}${locations.length > 5 ? '...' : ''}`);
    } else {
      displayJobsTable(jobs);
    }

    if (index < selectedArtifacts.length - 1) {
      console.log('‚îÄ'.repeat(80));
      console.log();
    }
  });
}

// Execute if run directly
if (import.meta.url === `file://${process.argv[1]}`) {
  main();
}

export { findArtifacts, filterJobs, searchJobs, calculateStats };